{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GROQ_API_KEY=\"\"\n",
    "HF_TOKEN = \"\"\n",
    "REQUIREMENTS_FOLDER = \"../projects/Aloha/requirements.txt\"\n",
    "NEO4J_USERNAME = \"\"\n",
    "NEO4J_PASSWORD = \"\"\n",
    "NEO4J_URL = \"bolt://localhost:7687\"\n",
    "KG_FOLDER = \"../kg/aloha\"\n",
    "INDEX_ID = \"\"\n",
    "MODEL = \"llama-3.1-8b-instant\"\n",
    "READ = False\n",
    "USE_BACKEND = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "llm = Groq(model=MODEL, api_key=GROQ_API_KEY, base_url=\"https://api.groq.com/openai/v1\")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.graph_stores.neo4j import Neo4jGraphStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "if USE_BACKEND:\n",
    "    graph_store = Neo4jGraphStore(\n",
    "        username=NEO4J_USERNAME,\n",
    "        password=NEO4J_PASSWORD,\n",
    "        url=NEO4J_URL,\n",
    "    )\n",
    "else: \n",
    "    graph_store = SimpleGraphStore()\n",
    "\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store, persist_dir=KG_FOLDER if READ else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocess requirements file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "with open(REQUIREMENTS_FOLDER, 'r') as f:\n",
    "    requirements = f.read()\n",
    "\n",
    "sentences = sent_tokenize(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Verma, K., & Kass, A. (2008). Requirements Analysis Tool: A Tool for Automatically Analyzing Software Requirements Documents. The Semantic Web - ISWC 2008, 751–763. doi:10.1007/978-3-540-88564-1_48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "formatted_requirements = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    prompt = f\"\"\"\n",
    "    You are a software analyst. Rewrite the following sentence into the appropriate requirement format, and **only return**:\n",
    "    \n",
    "    1. The rewritten requirement line.\n",
    "    2. If it is a StandardRequirement, return a second line: Agent: <agent>\n",
    "    \n",
    "    Do not include any explanations, reasoning, or extra commentary. Return exactly one or two lines only.\n",
    "    \n",
    "    Sentence: \"{sentence}\"\n",
    "    \n",
    "    Requirement Format Rules:\n",
    "    \n",
    "    1. **Standard Requirement**\n",
    "       Format: StandardRequirement: <agent> <modal word> <action> <rest>\n",
    "       Example: StandardRequirement: The system shall generate profit reports.\n",
    "       → Also return: Agent: The system\n",
    "    \n",
    "    2. **Conditional Requirement**\n",
    "       Format: ConditionalRequirement: if <condition> then <StandardRequirement>\n",
    "       Example: ConditionalRequirement: if the user enters the wrong password then the system shall send an error message.\n",
    "       → Do not return the agent separately.\n",
    "    \n",
    "    3. **Business Rule**\n",
    "       Format: BusinessRule: <rule>\n",
    "       Example: BusinessRule: Only administrators can access the payroll database.\n",
    "       → Do not return the agent separately.\n",
    "       - Treat all requirements that start with “all”, “only” and “exactly” as business rules\n",
    "    \n",
    "    Begin now:\"\"\"\n",
    "    output = llm.complete(prompt).text\n",
    "    print(f\"Original: {sentence}\")\n",
    "    print(f\"Response: {output}\")\n",
    "    print(\"----\")\n",
    "    formatted_requirements.append(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_standard_requirements(llm_outputs):\n",
    "    results = []\n",
    "    for output in llm_outputs:\n",
    "        lines = output.strip().splitlines()\n",
    "        for requirement_type in [\"StandardRequirement:\", \"ConditionalRequirement:\"]:\n",
    "            if lines and lines[0].startswith(requirement_type):\n",
    "                req_line = lines[0].replace(requirement_type, \"\").strip()\n",
    "                agent_line = None\n",
    "                if len(lines) > 1 and lines[1].startswith(\"Agent:\"):\n",
    "                    agent_line = lines[1].replace(\"Agent:\", \"\").strip()\n",
    "                results.append({\n",
    "                    \"requirement\": req_line,\n",
    "                    \"agent\": agent_line\n",
    "                })\n",
    "\n",
    "    return results\n",
    "reqs = parse_standard_requirements(formatted_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import Document\n",
    "\n",
    "nodes = [TextNode(text=req.get(\"requirement\"), metadata={\"id\": f\"REQ-{i+1}\", \"agent\": req.get(\"agent\")}) for i, req in enumerate(reqs)]\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "documents = [Document(text=req.get(\"requirement\")) for req in reqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Alt-1: Model graph as requirements relationships. \n",
    "Friedenthal, Sanford & Moore, Alan & Steiner, Rick. (2012). Modeling Text-Based Requirements and Their Relationship to Design. 10.1016/B978-0-12-385206-9.00013-2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify_relationship(req_a: str, req_b: str):\n",
    "    prompt = f\"\"\"\n",
    "            You are a software engineer analyzing software requirements. \n",
    "            Given the two requirements below, determine their relationship.\n",
    "            Choose one of: \n",
    "            - derived_from: Requirement A derives from Requirement B, meaning Requirement A is detailing Requirement B. \n",
    "            - depends_on: Requirement A depends on Requirement B \n",
    "            - unrelated: There is no relation between Requirement A and Requirement B\n",
    "            \n",
    "            Requirement A: {req_a}\n",
    "            Requirement B: {req_b}\n",
    "\n",
    "            Output format:\n",
    "            Relationship: <relationship_type>\n",
    "            \"\"\"\n",
    "\n",
    "    response = llm.complete(prompt).text.strip().lower()\n",
    "    match = re.search(r'relationship type:\\s*`(\\w+)`', response, re.IGNORECASE)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "retriever = vector_index.as_retriever(similarity_top_k=10)\n",
    "relationships = []\n",
    "\n",
    "for node in nodes:\n",
    "    similar = retriever.retrieve(node.text)\n",
    "    for sim in similar:\n",
    "        src_id = node.metadata[\"id\"]\n",
    "        tgt_id = sim.node.metadata[\"id\"]\n",
    "        if src_id != tgt_id:\n",
    "            relation = classify_relationship(node.text, sim.node.text)\n",
    "            print(relation)\n",
    "            if relation:\n",
    "                relationships.append({\n",
    "                    \"source\": src_id,\n",
    "                    \"source_requirement\": node.text,\n",
    "                    \"target\": tgt_id,\n",
    "                    \"target_requirement\": sim.node.text,\n",
    "                    \"relation\": relation\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Alt-2: Model requirements as a Conceptual Graph for requirements\n",
    "Jaramillo, C. M. Z., Gelbukh, A., & Isaza, F. A. (2006). Pre-conceptual Schema: A Conceptual-Graph-Like Knowledge Representation for Requirements Elicitation. MICAI 2006: Advances in Artificial Intelligence, 27–37. doi:10.1007/11925231_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.base.response.schema import Response\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "class ConnectionArc(BaseModel):\n",
    "    from_: str \n",
    "    to: str\n",
    "\n",
    "class ImplicationArc(BaseModel):\n",
    "    from_: str\n",
    "    to: str\n",
    "    label: Optional[Literal[\"yes\", \"no\"]] = \"yes\"\n",
    "\n",
    "class CRGModel(BaseModel):\n",
    "    requirement_id: str\n",
    "    requirement_text: str\n",
    "    concepts: List[str]\n",
    "    dynamic_relationships: List[str]\n",
    "    structural_relationships: List[str]\n",
    "    conditionals: List[str]\n",
    "    connection_arcs: List[ConnectionArc]\n",
    "    implication_arcs: List[ImplicationArc]\n",
    "\n",
    "prompt_template = PromptTemplate(\"\"\"\n",
    "    You are a requirements modeling assistant. Your task is to extract a Conceptual Requirement Graph (CRG) from a natural language software requirement. Use the following definitions and rules to structure your output. Return your results as JSON.\n",
    "    \n",
    "    Definitions:\n",
    "    \n",
    "    Node Types\n",
    "    - Concept: A noun representing an entity, person, thing, or property (e.g., user, profile, post).\n",
    "    - Dynamic Relationship: An action verb representing a user/system operation (e.g., display, login, register).\n",
    "    - Structural Relationship: A relationship with the label \"is\" or \"has\" (e.g., user _has_ profile).\n",
    "    - Conditional: A logical condition that must be true before an action can occur (e.g., user is logged in).\n",
    "    \n",
    "    Edge Types\n",
    "    - Connection Arc: Links a concept to a relationship or vice versa (no label).\n",
    "    - Implication Arc: Links a dynamic relationship or conditional to a dynamic relationship. Label it \"yes\" or \"no\" (default: \"yes\").\n",
    "    \n",
    "    Topology Rules\n",
    "    - Each concept must be connected via a connection arc.\n",
    "    - A dynamic relationship must have exactly one incoming and one outgoing connection arc (to concepts).\n",
    "    - A structural relationship must have one incoming and one or more outgoing connection arcs (to concepts).\n",
    "    - A conditional has no incoming arcs and one or more outgoing implication arcs (to dynamic relationships).\n",
    "    \n",
    "    Labeling Rules\n",
    "    - Concepts are labeled with nouns.\n",
    "    - Dynamic relationships use action verbs.\n",
    "    - Structural relationships are labeled \"is\" or \"has\".\n",
    "    - Conditionals are logical expressions.\n",
    "    - Implication arcs are labeled \"yes\" or \"no\".\n",
    "    \n",
    "    Guidelines\n",
    "    - Use consistent labels for repeating concepts.\n",
    "    - Include implicit conditionals if implied.\n",
    "    - Do not infer extra relationships not clearly expressed in the requirement.\n",
    "    - Every node and arc must follow the defined topological and labeling rules.\n",
    "    \n",
    "    \n",
    "    Requirement ID: {requirement_id}\n",
    "    Requirement Text: {requirement_text}\n",
    "    \n",
    "    Your response:\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def crg_to_triplets(crg: CRGModel) -> List[Tuple[str, str, str]]:\n",
    "    triplets = []\n",
    "    \n",
    "    for concept in crg.concepts:\n",
    "        triplets.append((concept, \"is_a\", \"Concept\"))\n",
    "\n",
    "    for action in crg.dynamic_relationships:\n",
    "        triplets.append((action, \"is_a\", \"Action\"))\n",
    "\n",
    "    for relation in crg.structural_relationships:\n",
    "        triplets.append((relation, \"is_a\", \"StructuralRelationship\"))\n",
    "\n",
    "    for cond in crg.conditionals:\n",
    "        triplets.append((cond, \"is_a\", \"Condition\"))\n",
    "\n",
    "    for arc in crg.connection_arcs:\n",
    "        triplets.append((arc.from_, \"connects_to\", arc.to))\n",
    "\n",
    "    for arc in crg.implication_arcs:\n",
    "        label = arc.label if arc.label else \"yes\"\n",
    "        triplets.append((arc.from_, f\"implies_{label}\", arc.to))\n",
    "\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_triplets = []\n",
    "\n",
    "sllm = llm.as_structured_llm(output_cls=CRGModel)\n",
    "\n",
    "for i, req in enumerate(reqs):\n",
    "    prompt = prompt_template.format(\n",
    "        requirement_id=f\"REQ-{i}\",\n",
    "        requirement_text=req.get(\"requirement\")\n",
    "    )\n",
    "    all_triplets.extend(crg_to_triplets(sllm.complete(prompt).raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices.loading import load_index_from_storage\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "\n",
    "if READ:\n",
    "    kg_index = load_index_from_storage(storage_context=storage_context, index_id=INDEX_ID)\n",
    "else:\n",
    "    if USE_BACKEND:\n",
    "        graph_store.query(\"MATCH (n) DETACH DELETE n\")\n",
    "    \n",
    "    kg_index = KnowledgeGraphIndex([], storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alt-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for rel in relationships:\n",
    "    if rel[\"relation\"] != \"unrelated\":\n",
    "        graph_store.upsert_triplet(rel[\"source_requirement\"], rel[\"relation\"], rel[\"target_requirement\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def normalize_concept(name: str) -> str:\n",
    "    doc = nlp(name.lower())\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "for triplet in all_triplets:\n",
    "    graph_store.upsert_triplet(normalize_concept(triplet[0]), triplet[1], normalize_concept(triplet[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query_engine = kg_index.as_query_engine()\n",
    "\n",
    "print(\"What actions require a user to be logged in?\")\n",
    "response = query_engine.query(\"What actions require a user to be logged in?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
